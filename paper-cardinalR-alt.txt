# Chunk label: layouts --------------------
## Alt-text: A multi-panel scatterplot compares six 2D embeddings of the same dataset, each panel showing points arranged into clusters in an X–Y plane without explicit numeric axis labels (coordinates are abstract embedding dimensions). In the t-SNE panel, points form six compact, clearly separated clusters with very small gaps between clusters, indicating strong preservation of both local neighborhoods and overall global arrangement. UMAP and PaCMAP panels also show six visually distinct clusters, moderately well-separated, suggesting reasonable but slightly less faithful structure preservation compared with t-SNE. The PHATE panel shows clusters with more curved, non-linear shapes and less resemblance to the original cluster geometry, while TriMAP shows effectively three larger clusters at relatively small distances from each other, implying poorer separation of the original six groups. The PCA panel shows elongated or overlapping point clouds with no clear non-linear separation between all six clusters, indicating that the linear projection fails to capture the underlying non-linear structure.

Assumptions: I assume each method is displayed in its own facet panel in a single figure, that axes are unlabelled generic embedding dimensions with similar scales across panels, and that all points represent the same observations colored or grouped consistently into six clusters, even though specific colors or legends are not described in the prompt.

Checklist:
1. Identified chart type. YES  
2. Named axes and variables. YES  
3. Mentioned approximate ranges or scales (where meaningful). YES  
4. Described data mappings (e.g. colour/shape/size/facets). YES  
5. Described main patterns, trends, or clusters. YES  
6. Explicitly noted any assumptions. YES

## Caption (for reference): As shown in Figure \@ref(fig:fig-nldr-layouts), tSNE (Figure \@ref(fig:fig-nldr-layouts) a) achieved the lowest HBE across bin widths (mostly tiny), indicating high preservation of both local and global structures. Its layout displays well-separated clusters with minimal inter-cluster distances, making it the most faithful representation of the underlying data structure. UMAP and PaCMAP (Figure \@ref(fig:fig-nldr-layouts) b and e) produced moderately accurate embeddings, although the six clusters appear more well-separated, while PHATE (Figure \@ref(fig:fig-nldr-layouts) c) show non-linear cluster structures irrespective of the original structure. Also, TriMAP (Figure \@ref(fig:fig-nldr-layouts) d) has high HBE, and show three clusters with small distances. PCA (Figure \@ref(fig:fig-nldr-layouts) f) failed to capture the non-linear geometry, leading to the highest HBE.

## Usage: BrailleR, Cummulated cost: NA, Cummulated token usage: 0


# Chunk label: fig-cluster-stats --------------------
## Alt-text: A multi-panel line chart displays six cluster validation metrics as a function of the number of clusters (k = 2 to 10) for three clustering methods: k-means, hierarchical, and model-based clustering. The horizontal axis in every panel is the number of clusters (integer values from 2 to 10). The vertical axis shows the value of a given metric, on a method-specific numeric scale (exact ranges vary by panel but all rise from low to high values). Within each panel (one for each metric: Pearson gamma, Calinski–Harabasz index, Dunn index, WB ratio, within-cluster sum of squares, and S-index), three lines—distinguished by colour or line type—represent the three clustering methods across k. For the “higher is better” metrics (Pearson gamma, Calinski–Harabasz, Dunn), lines increase sharply up to roughly 4–5 clusters and then flatten or vary modestly, with peaks often at 4 or 5 clusters; k-means usually attains slightly higher values than hierarchical and model-based. For the “lower is better” metrics (WB ratio and within-cluster sum of squares), all three methods show steadily decreasing curves as k increases, with a noticeable bend or elbow around k = 5. The S-index panel shows more method-specific optima: the k-means line peaks around 4 clusters, while hierarchical and model-based lines have local optima at other k values (such as 3, 6, or 8). Across panels, the main visual impression is that a 4–5 cluster solution is often favoured, and k-means tends to perform marginally better across most metrics and numbers of clusters.

Assumptions: I assume each metric is shown in a separate facet panel using line plots with discrete x-axis labels from 2 to 10, that each clustering method is encoded by a distinct colour or line style with a legend, and that no raw data points, confidence intervals, or error bars are drawn beyond the lines.

Checklist:
1. Identified chart type. YES  
2. Named axes and variables. YES  
3. Mentioned approximate ranges or scales (where meaningful). YES  
4. Described data mappings (e.g. colour/shape/size/facets). YES  
5. Described main patterns, trends, or clusters. YES  
6. Explicitly noted any assumptions. YES

## Caption (for reference): Figure \@ref(fig:fig-cluster-stats) shows a selection of cluster metrics for $2-10$ clusters for each of the methods, $k$-means, hierarchical, and model-based. As is typical, the suggestion of the best solution varies between cluster statistics. Although the metrics differ in their preferences, several show consistent support for a $4-5$ cluster solution. Pearson gamma (`pearsongamma`) increases sharply up to five clusters before levelling off, Calinski–Harabasz index (`ch`) increases sharply from 4 to 5 clusters and Dunn (`dunn2`) has a maximum at 5 for two methods and at 4 for $k$-means. All of these are interpreted as higher is better. With the other three, lower is better. WB ratio (`wbratio`) and within-cluster sum of squares (`within.cluster.ss`) steadily decline with number of clusters, possibly elbowing around 5 clusters. The S-index (`sindex`) is optimised at 4 clusters for $k$-means, 3, 6 or 8 for hierarchical clustering, and 4 or 8 for model-based. Overall, $k$-means performs slightly better than the hierarchical and model-based clustering across most metrics and number of clusters.

## Usage: BrailleR, Cummulated cost: NA, Cummulated token usage: 0
