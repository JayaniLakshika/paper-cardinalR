# Chunk label: layouts --------------------
## Alt-text: A multi-panel scatterplot figure compares 2D embeddings of the same dataset produced by six nonlinear dimensionality reduction methods: t-SNE, UMAP, PHATE, TriMAP, PaCMAP, and PCA. Each panel plots two embedding coordinates on the x- and y-axes (both roughly centred around zero, spanning a few arbitrary units) with points representing individual data samples; colours (or visually distinct point groups) indicate six underlying clusters.  

In the t-SNE panel, six compact clusters are clearly separated with small between-cluster distances, forming distinct, well-isolated groups. UMAP and PaCMAP also show six clusters that are visually separated, but with slightly more overlap and less uniform spacing between clusters than t-SNE. PHATE displays elongated, curved, or branched cluster shapes, indicating non-linear structures that deviate from the original discrete cluster geometry. TriMAP shows only three visible groups with relatively small distances between them, suggesting substantial merging of the original six clusters. PCA produces a nearly linear or oval-shaped arrangement with heavily overlapping clusters, indicating poor preservation of the original non-linear and multi-cluster structure.

Assumptions: The figure is arranged as a 2×3 grid (a–f) with t-SNE, UMAP, PHATE, TriMAP, PaCMAP, and PCA in that order; clusters are distinguished primarily by colour; axis scales are similar across panels but are in arbitrary embedding units and roughly symmetric around zero.

Checklist  
1. Identified chart type. YES  
2. Named axes and variables. YES  
3. Mentioned approximate ranges or scales (where meaningful). YES  
4. Described data mappings (e.g. colour/shape/size/facets). YES  
5. Described main patterns, trends, or clusters. YES  
6. Explicitly noted any assumptions. YES

## Caption (for reference): As shown in Figure \@ref(fig:fig-nldr-layouts), tSNE (Figure \@ref(fig:fig-nldr-layouts) a) achieved the lowest HBE across bin widths (mostly tiny), indicating high preservation of both local and global structures. Its layout displays well-separated clusters with minimal inter-cluster distances, making it the most faithful representation of the underlying data structure. UMAP and PaCMAP (Figure \@ref(fig:fig-nldr-layouts) b and e) produced moderately accurate embeddings, although the six clusters appear more well-separated, while PHATE (Figure \@ref(fig:fig-nldr-layouts) c) show non-linear cluster structures irrespective of the original structure. Also, TriMAP (Figure \@ref(fig:fig-nldr-layouts) d) has high HBE, and show three clusters with small distances. PCA (Figure \@ref(fig:fig-nldr-layouts) f) failed to capture the non-linear geometry, leading to the highest HBE.

## Usage: BrailleR, Cummulated cost: NA, Cummulated token usage: 0


# Chunk label: fig-cluster-stats --------------------
## Alt-text: A multi-panel line chart displays six cluster validity metrics plotted against the number of clusters (k = 2 to 10) for three clustering methods: k-means, hierarchical, and model-based. The x-axis shows the number of clusters, from 2 on the left to 10 on the right. The y-axis shows the value of each metric on its own scale, which differs by panel (e.g., correlation-like values for Pearson gamma, index values for Calinski–Harabasz and Dunn, ratios or sums for WB ratio and within-cluster sum of squares, and index scores for S-index). Within each panel, three lines (distinguished by colour or line type) represent the three clustering methods.

Across metrics where higher is better (Pearson gamma, Calinski–Harabasz, Dunn), lines generally rise steeply as k increases to about 4 or 5, then level off or fluctuate, with peaks often around 4–5 clusters. In the lower-is-better metrics (WB ratio and within-cluster sum of squares), all methods show a steady decline in values as k increases, with a noticeable change in curvature—an elbow—around 5 clusters. The S-index lines show method-specific optima at different k values, but commonly highlight solutions around 3–4 and sometimes 6 or 8 clusters. Overall, the k-means lines tend to be slightly more favourable (higher when higher is better, and lower when lower is better) than hierarchical and model-based clustering across most k values, and multiple metrics collectively suggest that 4 or 5 clusters provide a reasonable balance.

Assumptions: The figure is arranged as a 2×3 grid of small multiples, one panel per metric, all sharing the same x-axis range (2–10 clusters); methods are distinguished by colour or line style and possibly indicated in a legend; exact numerical y-axis ranges are not specified and are treated as method- and metric-specific.

Checklist  
1. Identified chart type. YES  
2. Named axes and variables. YES  
3. Mentioned approximate ranges or scales (where meaningful). YES  
4. Described data mappings (e.g. colour/shape/size/facets). YES  
5. Described main patterns, trends, or clusters. YES  
6. Explicitly noted any assumptions. YES

## Caption (for reference): Figure \@ref(fig:fig-cluster-stats) shows a selection of cluster metrics for $2-10$ clusters for each of the methods, $k$-means, hierarchical, and model-based. As is typical, the suggestion of the best solution varies between cluster statistics. Although the metrics differ in their preferences, several show consistent support for a $4-5$ cluster solution. Pearson gamma (`pearsongamma`) increases sharply up to five clusters before levelling off, Calinski–Harabasz index (`ch`) increases sharply from 4 to 5 clusters and Dunn (`dunn2`) has a maximum at 5 for two methods and at 4 for $k$-means. All of these are interpreted as higher is better. With the other three, lower is better. WB ratio (`wbratio`) and within-cluster sum of squares (`within.cluster.ss`) steadily decline with number of clusters, possibly elbowing around 5 clusters. The S-index (`sindex`) is optimised at 4 clusters for $k$-means, 3, 6 or 8 for hierarchical clustering, and 4 or 8 for model-based. Overall, $k$-means performs slightly better than the hierarchical and model-based clustering across most metrics and number of clusters.

## Usage: BrailleR, Cummulated cost: NA, Cummulated token usage: 0
