---
title: "cardinalR: Generating interesting high-dimensional data structures"
abstract: >
  A high-dimensional dataset is one where each observation is described by many features, or dimensions, with associations between them. These datasets contain nonlinear manifolds in image and speech recognition, clusters in genomics and forensic analysis, and sparse distributions in text mining. Data with a variety of structures can be generated using mathematical functions and statistical distributions to create test datasets. High-dimensional data structures are useful for testing, validating, and improving algorithms used in dimensionality reduction, clustering, machine learning, and visualization. Their controlled complexity allows researchers to understand challenges posed in data analysis and helps to develop robust analytical methods across diverse scientific fields like bioinformatics, machine learning, and forensic science. Functions to generate a large variety of structures in high dimensions are organized into the R package `cardinalR`, along with some already generated examples, adding to the existing toolset of benchmark datasets for evaluating algorithms.
draft: true
author:  
  - name: Jayani P. Gamage
    affiliation: Monash University
    address: Department of Econometrics and Business Statistics, VIC 3800 Australia
    url: https://jayanilakshika.netlify.app/
    orcid: 0000-0002-6265-6481
    email:  \email{jayani.piyadigamage@monash.edu}
  - name: Dianne Cook
    affiliation: Monash University
    address: Department of Econometrics and Business Statistics, VIC 3800 Australia
    url: http://www.dicook.org/
    email: dicook@monash.edu
    orcid: 0000-0002-3813-7155
  - name: Paul Harrison
    affiliation: Monash University
    address: MGBP, BDInstitute, VIC 3800 Australia
    email: paul.harrison@monash.edu
    orcid: 0000-0002-3980-268X
  - name: Michael Lydeamore
    affiliation: Monash University
    address: Department of Econometrics and Business Statistics, VIC 3800 Australia
    email: michael.lydeamore@monash.edu
    orcid: 0000-0001-6515-827X
  - name: Thiyanga S. Talagala
    affiliation: University of Sri Jayewardenepura
    address: Department of Statistics, Gangodawila, Nugegoda 10100 Sri Lanka
    url: https://thiyanga.netlify.app/
    email: ttalagala@sjp.ac.lk
    orcid: 0000-0002-0656-9789
type: package
creative_commons: CC BY
date: "`r Sys.Date()`"
preamble: >
  \usepackage{amsmath}
  \usepackage{array}
  \usepackage{float}
  \newcommand\pD{$p\text{-}D$}
  \newcommand\gD{$2\text{-}D$}
output: 
 rjtools::rjournal_article:
    keep_md: true
bibliography: paper-cardinalR.bib
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
options(repos = "https://cloud.r-project.org") ## set up CRAN mirror
knitr::opts_chunk$set(
  echo = FALSE,
  cache=FALSE, 
  message=FALSE, 
  warning=FALSE,
  out.width = "100%",
  fig.pos = "!")

```

```{r set-seed}
set.seed(20240412)
```

```{r install-libraries, include=FALSE, warning=FALSE, echo=FALSE}

options(repos = c(CRAN = "https://cran.rstudio.com")) # Setup mirror

packages_to_check <- c("remotes", "cardinalR", "tidyverse", "kableExtra", "geozoo", "patchwork", "colorspace")

for (pkg in packages_to_check) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    message(paste("Installing package:", pkg))
    install.packages(pkg)
  } else {
    installed_version <- packageVersion(pkg)
    available_version <- tryCatch({
      utils::packageDescription(pkg)$Version
    }, error = function(e) NA) # Handle cases where package info isn't readily available

    if (!is.na(available_version) && installed_version < package_version(available_version)) {
      message(paste("A newer version of package", pkg, "is available. Updating..."))
      install.packages(pkg)
    } else {
      message(paste("Package", pkg, "is up-to-date (version", installed_version, ")."))
    }
  }
}

```

```{r load-libraries}
library(cardinalR)
library(tidyverse)
library(kableExtra)
library(geozoo)
library(patchwork)
library(colorspace)
library(crosstalk)
```

```{r}
#| label: plot-theme
theme_set(theme_linedraw() +
   theme(
     aspect.ratio = 1,
     plot.background = element_rect(fill = 'transparent', colour = NA),
     plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
     panel.background = element_rect(fill = 'transparent', 
                                     colour = NA),
     panel.grid.major = element_blank(), 
     panel.grid.minor = element_blank(), 
     axis.title.x = element_blank(), axis.title.y = element_blank(),
     axis.text.x = element_blank(), axis.ticks.x = element_blank(),
     axis.text.y = element_blank(), axis.ticks.y = element_blank(),
     legend.background = element_rect(fill = 'transparent', 
                                      colour = NA),
     legend.key = element_rect(fill = 'transparent', 
                               colour = NA),
     legend.position = "bottom", 
     legend.title = element_blank(), 
     legend.text = element_text(size=4),
     legend.key.height = unit(0.25, 'cm'),
     legend.key.width = unit(0.25, 'cm'),
     plot.margin = margin(0, 0, 0, 0)
   )
)
```

```{r}
#| label: import-scripts
source("scripts/additional_functions.R")
```

# Introduction

Generating synthetic datasets with clearly defined geometric properties is useful for evaluating and benchmarking algorithms in various fields, such as machine learning, data mining, and computational biology. Researchers often need to generate data with specific dimensions, noise characteristics, and complex underlying structures to test the performance and robustness of their methods. There are numerous packages available in R for generating synthetic data, each designed with unique characteristics and focus areas.The `geozoo` package (@barret2016) offers a large collection of geometric objects, allowing users to create and analyze specific shapes, primarily in lower-dimensional spaces. The package is `snedata` (@james2025), which provides tools for generating simplified datasets useful for evaluating dimensionality reduction techniques like tSNE, often focusing on understanding and evaluating low-dimensional embeddings of complex data structures. Additionally, `splatter` (@luke2017) is designed to simulate complex biological data, capturing field-specific nuances such as batch effects and differential expression. In contrast, `mlbench` (@friedrich2024) includes a collection of well-known benchmark datasets commonly associated with established classification or regression challenges. The `surreal` package (@james2024) implements the "Residual (Sur)Realism" algorithm (@leonard2007) to generate datasets that embed hidden images or text into residual plots, providing engaging visual demonstrations for teaching model diagnostics. Meanwhile, the `DHARMa` package (@florian2024) adopts a simulation-based approach to create scaled quantile residuals for generalized linear (mixed) models and related frameworks, supporting model diagnostics through intuitive residuals, plots, and tests for common misspecification issues. 

<!--https://cran.r-project.org/web/packages/surreal/index.html-->
<!--https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html-->

While these packages are valuable, their scope is often limited to specific applications or low-dimensional structures. To address this gap, this paper introduces the `cardinalR` R package. This package provides a collection of functions designed to generate customizable data structures in any number of dimensions, starting from basic geometric shapes. `cardinalR` offers important functionalities that extend beyond the capabilities of existing tools, allowing users to: (i) construct high-dimensional datasets based on geometric shapes, including the option to enhance dimensionality by adding controlled noise dimensions; (ii) introduce adjustable levels of background noise to these structures; and (iii) combine high-dimensional datasets into a single multi-faceted, clustered dataset in a space of arbitrary dimension. By using clearly defined geometric shapes and controllable characteristics such as number of dimensions, sample size; `cardinalR` allows researchers to generate transparent and interpretable synthetic datasets useful for evaluating the performance of nonlinear dimensionality reduction (NLDR) methods, clustering algorithms, and visualization techniques. Moreover, these datasets can serve as benchmark examples for exploring how different algorithmic choices affect the identification or representation of cluster and manifold structures in high-dimensional spaces.

The paper is organized as follows. In the next section, we introduce the implementation of the `cardinalR` package on GitHub, including a demonstration of the package's key functions. We illustrate how a clustering data structure affects the dimension reductions in the Application section. Finally, we give a brief conclusion of the paper and discuss potential opportunities for the use of our data collection.


# Implementation

The `cardinalR` R package is available on GitHub at [JayaniLakshika/cardinalR](https://github.com/JayaniLakshika/cardinalR).

<!-- ## Web site -->

<!-- More documentation of the package can be found at the web site [https://jayanilakshika.github.io/cardinalR/](https://jayanilakshika.github.io/cardinalR/). -->

## Usage

### Main function

The main function of the package is `gen_multicluster()`, which generates datasets consisting of multiple clusters with user-specified characteristics. Users can control the number of clusters (`k`), and the number of points in each cluster (`n`). Each cluster can take on a different geometric shape (e.g., Gaussian, cone, uniform cube) by specifying the corresponding generator function (`shape`), can be scaled to adjust its spread, rotated using custom rotation matrices (`rotation`), and positioned at defined centroids (`loc`). The function ensures flexibility in cluster location and orientation, allowing users to simulate complex high-dimensional structures. 

To maintain consistency across generators, the function identifies the arguments required by each chosen generator function and supplies only those arguments that are valid for that specific generator. This design enables the combination of cluster types with differing parameter requirements within the same dataset. When clusters are generated with fewer dimensions than others, the function augments the lower-dimensional clusters with additional Gaussian noise variables so that all clusters are represented in the same dimensional space. These noise dimensions are drawn independently from normal distributions

$$
X \sim \mathcal{N}(m, s^2),
$$

where the mean ($m$) is set to the average of the cluster coordinates and the standard deviation ($s$) defaults to $0.2$.

An optional argument, `is_bkg`, adds background noise drawn from a multivariate normal distribution centered on the dataset’s overall mean with standard deviations matching the observed spread. Extra arguments (`...`) can be passed to cluster generators, allowing further control over per-cluster characteristics like radius of the sphere.

The main arguments of the `gen_multicluster()` function are shown in Table `r knitr::asis_output(ifelse(knitr::is_html_output(), '\\@ref(tab:main-tb-html)', '\\@ref(tab:main-tb-pdf)'))`.

```{r}
main_tb <- tibble(arg = c("n",
                          "k",
                          "loc",
                          "scale",
                          "shape",
                          "rotation",
                          "is_bkg"),
                  type = c("numeric (vector)",
                           "numeric",
                           "numeric (matrix)",
                           "numeric (vector)",
                           "character (vector)",
                           "numeric (list)",
                           "boolean"),
                        exp = c("Number of points in each cluster.",
                                "Number of clusters.",
                                "Locations/centroids of clusters.",
                                "Scaling factors of clusters.",
                                "Shapes of clusters.",
                                "Rotation matrices, one per cluster.",
                                "Background noise should exist or not."))
```

```{r main-tb-html, eval=knitr::is_html_output()}
main_tb |> 
  kable(caption = "The main arguments for `gen_multicluster()`.", col.names = c("Argument", "Type", "Explanation")) 
```

```{r main-tb-pdf, eval=knitr::is_latex_output()}
main_tb |> 
  kable(caption = "The main arguments for gen\\_multicluster().", format="latex", col.names = c("Argument", "Type", "Explanation"), booktabs = T, table.pos = "H")  |>
  column_spec(1, width = "2cm") |>
  column_spec(2, width = "3cm") |>
  column_spec(3, width = "8cm")
```

### Shape generators

The shape generators form the foundation of the package, providing a collection of functions to create synthetic data structures based on simple, well-defined geometric structures. These include fundamental shapes such as cones, pyramids, spheres, grids, and branching structures. If a shape is not inherently defined in more than three dimensions, additional noise dimensions can be added to embed the structure into higher-dimensional space. Users can specify how these noise dimensions are generated (e.g., Gaussian, wavy) (`noise_fun`), offering control over the embedding process. All shape generators allow the user to define the number of points (`n`) and dimensions (`p`), and most include additional arguments to customize specific characteristics of the structure. 

#### Cone

To simulate a cone-shaped structure in arbitrary dimensions (`r knitr::asis_output(if (knitr::is_html_output()) { "Figure \\@ref(fig:cone)"} else { "Figure \\@ref(fig:cone-proj)"})`), we define a function `gen_cone(n, p, h, ratio)`, which creates a high-dimensional cone with options for a sharp or blunted apex, allowing for a dense concentration of points near the tip.

This function generates $n$ points in $p\text{-}D$, where the last dimension, $X_p$, represents the height along the cone's axis, and the first $p-1$ dimensions define a shrinking hyperspherical cross-section toward the tip. Heights are sampled from a truncated exponential distribution, $X_p \sim \text{Exp}(\lambda = 2/h)$, capped at the cone height $h$, producing a higher density of points near the tip. At each height $X_p$, the radius of the cross-section decreases linearly from base to tip according to $r = r_{\text{min}} + (r_{\text{max}} - r_{\text{min}}) X_p / h$, where $r_{\text{min}} = \text{ratio}$ and $r_{\text{max}} = 1$.

For each point, a direction in the first $p-1$ dimensions is sampled uniformly on a $(p-1)$-dimensional hypersphere using generalized spherical coordinates. The radial coordinates are scaled by the height-dependent radius $r$, producing the conical taper. In three dimensions ($p = 3$), this results in a classical $3\text{-}D$ cone, while for $p > 3$, additional dimensions provide a smooth embedding into higher-dimensional space, preserving the conical structure.

```{r data-bluntedcone, echo=TRUE}
cone <- gen_cone(n = 1000, p = 4, h = 5, ratio = 0.5)
```

```{r}
cone_lang <- langevitour::langevitour(cone, levelColors = "black", enableControls = FALSE, width = "400px", height = "300px")
```

```{r cone-proj1}
scaled_data <- scale_data_manual(cone)

## First projection
projection <- cbind(
  c(0.22417,-0.02943,-0.02870,0.08418),
  c(-0.02715,0.18019,0.05053,0.15254))

proj_obj1 <- get_projection(projection = projection, 
                            proj_scale = 1.2, 
                            scaled_data = scaled_data, 
                            axis_param = list(limits = 0.25,
                                              axis_scaled = 3, 
                                              axis_pos_x = -0.2, 
                                              axis_pos_y = -0.2, 
                                              threshold = 0.022))

cone_proj1 <- plot_proj(
  proj_obj = proj_obj1, 
  point_param = c(1.5, 0.2, "#000000"), # size, alpha, color
  plot_limits = c(-0.25, 0.25), 
  title = "a1", 
  cex = 2, 
  axis_text_size = 5,
  is_color = FALSE)

```

```{r cone-proj2}

## Second projection
projection <- cbind(
    c(0.15591,0.17907,0.03198,0.04496),
    c(-0.15376,0.10435,0.15766,0.00547))

proj_obj2 <- get_projection(projection = projection, 
                            proj_scale = 1.2, 
                            scaled_data = scaled_data, 
                            axis_param = list(limits = 0.1,
                                              axis_scaled = 3, 
                                              axis_pos_x = -0.08, 
                                              axis_pos_y = -0.08, 
                                              threshold = 0.01))

cone_proj2 <- plot_proj(
  proj_obj = proj_obj2, 
  point_param = c(1.5, 0.2, "#000000"), # size, alpha, color
  plot_limits = c(-0.1, 0.12), 
  title = "a2", 
  cex = 2, 
  axis_text_size = 5,
  is_color = FALSE)

```

```{r cone-proj3}

## Third projection
projection <- cbind(
    c(-0.13548,0.13832,0.05991,-0.13544),
    c(0.08479,-0.10719,-0.01572,-0.20123))

proj_obj3 <- get_projection(projection = projection, 
                            proj_scale = 1.2, 
                            scaled_data = scaled_data, 
                            axis_param = list(limits = 0.25,
                                              axis_scaled = 3, 
                                              axis_pos_x = -0.25, 
                                              axis_pos_y = -0.25, 
                                              threshold = 0.016))

cone_proj3 <- plot_proj(
  proj_obj = proj_obj3, 
  point_param = c(1.5, 0.2, "#000000"), # size, alpha, color
  plot_limits = c(-0.3, 0.2), 
  title = "a3", 
  cex = 2, 
  axis_text_size = 5,
  is_color = FALSE)

```

```{r cone, eval=knitr::is_html_output(), fig.cap="`langevitour` output  of the `cone` data in $4\\text{-}D$."}

conefig <- bscols(
  htmltools::div(
    style = "display: grid; grid-template-columns: 1fr 1fr;",
    cone_lang
  ),
  device = "xs"
)

class(conefig) <- c(class(conefig), "htmlwidget")

conefig
```

```{r cone-proj, eval=knitr::is_latex_output(), fig.cap="Three $2\\text{-}D$ projections from $4\\text{-}D$, for the `cone` data."}
#| fig-width: 12
#| fig-height: 4

cone_proj1 + cone_proj2 + cone_proj3 +
  plot_layout(ncol = 3, guides = "collect") 
```

#### Linear

The `gen_longlinear(n, p)` function generates a high-dimensional dataset representing a long linear structure with noise. Each variable is formed as $X_i = \text{scale}_i \cdot (0,1,\dots,n{-}1 + \epsilon) + \text{shift}_i$, where $\text{scale}\_i \sim U(-10, 10)$ determines the orientation of the line in each dimension, $\text{shift}\_i \sim U(-300, 300)$ offsets the line to separate dimensions, and $\epsilon \sim N(0, (0.03n)^2)$ introduces Gaussian noise. 

```{r data-linear, echo=TRUE}
linear <- gen_longlinear(n = 1000, p = 4)
```

```{r}
linear_lang <- langevitour::langevitour(linear, levelColors = "black", enableControls = FALSE, width = "400px", height = "300px")
```

```{r linear-proj1}
scaled_data <- scale_data_manual(linear)

## First projection
projection <- cbind(
  c(0.53506,0.00763,0.00097,-0.10901),
  c(0.00896,0.52496,0.12597,0.08184))

proj_obj1 <- get_projection(projection = projection, 
                            proj_scale = 1.2, 
                            scaled_data = scaled_data, 
                            axis_param = list(limits = 0.6,
                                              axis_scaled = 1.2, 
                                              axis_pos_x = -0.55, 
                                              axis_pos_y = -0.55, 
                                              threshold = 0.022))

linear_proj1 <- plot_proj(
  proj_obj = proj_obj1, 
  point_param = c(1.5, 0.2, "#000000"), # size, alpha, color
  plot_limits = c(-0.65, 0.5), 
  title = "a1", 
  cex = 2, 
  axis_text_size = 5,
  is_color = FALSE)

```

```{r linear-proj2}

## Second projection
projection <- cbind(
  c(-0.06614,0.15134,-0.44278,0.27367),
  c(-0.50493,0.14388,0.14615,0.03486))

proj_obj2 <- get_projection(projection = projection, 
                            proj_scale = 1.2, 
                            scaled_data = scaled_data, 
                            axis_param = list(limits = 0.75,
                                              axis_scaled = 3, 
                                              axis_pos_x = -0.75, 
                                              axis_pos_y = -0.75, 
                                              threshold = 0.01))

linear_proj2 <- plot_proj(
  proj_obj = proj_obj2, 
  point_param = c(1.5, 0.2, "#000000"), # size, alpha, color
  plot_limits = c(-0.9, 0.6), 
  title = "a2", 
  cex = 2, 
  axis_text_size = 5,
  is_color = FALSE)

```

```{r linear-proj3}

## Third projection
projection <- cbind(
  c(0.10704,0.04822,-0.03416,0.53224),
  c(0.50329,0.07199,-0.16064,-0.11806))

proj_obj3 <- get_projection(projection = projection, 
                            proj_scale = 1.2, 
                            scaled_data = scaled_data, 
                            axis_param = list(limits = 0.9,
                                              axis_scaled = 1.5, 
                                              axis_pos_x = -0.55, 
                                              axis_pos_y = -0.55, 
                                              threshold = 0.02))

linear_proj3 <- plot_proj(
  proj_obj = proj_obj3, 
  point_param = c(1.5, 0.2, "#000000"), # size, alpha, color
  plot_limits = c(-0.7, 0.7), 
  title = "a3", 
  cex = 2, 
  axis_text_size = 5,
  is_color = FALSE)

```

```{r linear, eval=knitr::is_html_output(), fig.cap="`langevitour` output  of the `linear` data in $4\\text{-}D$."}

linearfig <- bscols(
  htmltools::div(
    style = "display: grid; grid-template-columns: 1fr 1fr;",
    linear_lang
  ),
  device = "xs"
)

class(linearfig) <- c(class(linearfig), "htmlwidget")

linearfig
```

```{r linear-proj, eval=knitr::is_latex_output(), fig.cap="Three $2\\text{-}D$ projections from $4\\text{-}D$, for the `linear` data."}
#| fig-width: 12
#| fig-height: 4

linear_proj1 + linear_proj2 + linear_proj3 +
  plot_layout(ncol = 3, guides = "collect") 
```

#### Gaussian

The `gen_gaussian(n, p, s)` function generates a multivariate Gaussian cloud in $p\text{-}D$, centered at the origin with user-defined covariance structure (`r knitr::asis_output(if (knitr::is_html_output()) { "Figure \\@ref(fig:gau)"} else { "Figure \\@ref(fig:gau-proj)"})`). Each point is independently drawn using the multivariate normal distribution with $X_i \sim N_p(\boldsymbol{0}, s)$, where $s$ is a user-defined $p \times p$ positive-definite matrix.

```{r data-gau, echo=TRUE}
gau <- gen_gaussian(n = 1000, p = 4, s = diag(4))
```

```{r}
gau_lang <- langevitour::langevitour(gau, levelColors = "black", enableControls = FALSE, width = "400px", height = "300px")
```

```{r gau-proj1}
scaled_data <- scale_data_manual(gau)

## First projection
projection <- cbind(
  c(0.53506,0.00763,0.00097,-0.10901),
  c(0.00896,0.52496,0.12597,0.08184))

proj_obj1 <- get_projection(projection = projection, 
                            proj_scale = 1.2, 
                            scaled_data = scaled_data, 
                            axis_param = list(limits = 0.7,
                                              axis_scaled = 1.2, 
                                              axis_pos_x = -0.5, 
                                              axis_pos_y = -0.5, 
                                              threshold = 0.022))

gau_proj1 <- plot_proj(
  proj_obj = proj_obj1, 
  point_param = c(1.5, 0.2, "#000000"), # size, alpha, color
  plot_limits = c(-0.65, 0.7), 
  title = "a1", 
  cex = 2, 
  axis_text_size = 5,
  is_color = FALSE)

```

```{r gau-proj2}

## Second projection
projection <- cbind(
  c(-0.06614,0.15134,-0.44278,0.27367),
  c(-0.50493,0.14388,0.14615,0.03486))

proj_obj2 <- get_projection(projection = projection, 
                            proj_scale = 1.2, 
                            scaled_data = scaled_data, 
                            axis_param = list(limits = 0.7,
                                              axis_scaled = 3, 
                                              axis_pos_x = -0.57, 
                                              axis_pos_y = -0.57, 
                                              threshold = 0.01))

gau_proj2 <- plot_proj(
  proj_obj = proj_obj2, 
  point_param = c(1.5, 0.2, "#000000"), # size, alpha, color
  plot_limits = c(-0.7, 0.6), 
  title = "a2", 
  cex = 2, 
  axis_text_size = 5,
  is_color = FALSE)

```

```{r gau-proj3}

## Third projection
projection <- cbind(
  c(0.10704,0.04822,-0.03416,0.53224),
  c(0.50329,0.07199,-0.16064,-0.11806))

proj_obj3 <- get_projection(projection = projection, 
                            proj_scale = 1.2, 
                            scaled_data = scaled_data, 
                            axis_param = list(limits = 0.6,
                                              axis_scaled = 1.5, 
                                              axis_pos_x = -0.6, 
                                              axis_pos_y = -0.6, 
                                              threshold = 0.016))

gau_proj3 <- plot_proj(
  proj_obj = proj_obj3, 
  point_param = c(1.5, 0.2, "#000000"), # size, alpha, color
  plot_limits = c(-0.7, 0.62), 
  title = "a3", 
  cex = 2, 
  axis_text_size = 5,
  is_color = FALSE)

```

```{r gau, eval=knitr::is_html_output(), fig.cap="`langevitour` output  of the `gau` data in $4\\text{-}D$."}

gaufig <- bscols(
  htmltools::div(
    style = "display: grid; grid-template-columns: 1fr 1fr;",
    gau_lang
  ),
  device = "xs"
)

class(gaufig) <- c(class(gaufig), "htmlwidget")

gaufig
```

```{r gau-proj, eval=knitr::is_latex_output(), fig.cap="Three $2\\text{-}D$ projections from $4\\text{-}D$, for the `gau` data."}
#| fig-width: 12
#| fig-height: 4

gau_proj1 + gau_proj2 + gau_proj3 +
  plot_layout(ncol = 3, guides = "collect") 
```

### Wrappers

### Generate noise dimensions

High-dimensional data structures often benefit from the addition of auxiliary noise dimensions, which can be used to assess the robustness of dimensionality reduction and clustering algorithms. The functions in this section provide flexible ways to generate random noise dimensions, ranging from purely random Gaussian variables to more structured, wavy patterns that mimic non-linear distortions in high-dimensional space. These functions can be applied independently or combined with other geometric structures to create complex simulated datasets. Table `r knitr::asis_output(ifelse(knitr::is_html_output(), '\\@ref(tab:noise-tb-html)', '\\@ref(tab:noise-tb-pdf)'))` details these functions.

```{r}
noise_fun_tb <- tibble(fun = c("gen_noisedims",
                            "gen_wavydims1",
                            "gen_wavydims2",
                            "gen_wavydims3"), 
                        exp = c("Gaussian noise dimensions with optional mean and standard deviation.",
                                "Wavy noise dimensions based on a user-specified theta sequence with added jitter.",
                                "Wavy noise dimensions using polynomial transformations of an existing dimension vector.",
                                "Wavy noise dimensions using a combination of polynomial and sine transformations based on the first three dimensions of a dataset."))
```

```{r noise-tb-html, eval=knitr::is_html_output()}
noise_fun_tb |> 
  kable(caption = "cardinalR noise dimensions generation functions", col.names = c("Function", "Explanation")) 
```

```{r noise-tb-pdf, eval=knitr::is_latex_output()}
noise_fun_tb |> 
  kable(caption = "cardinalR noise dimensions generation functions", format="latex", col.names = c("Function", "Explanation"), booktabs = T)  |>
  column_spec(1, width = "4cm") |>
  column_spec(2, width = "8cm")
```

The `gen_noisedims(n, p, m, s)` function generates $p$ independent Gaussian noise dimensions,

$$
X_j \sim N(m_j, s_j^2), \quad j = 1, \dots, p,
$$

with odd-numbered dimensions multiplied by $-1$ to introduce sign alternation, enhancing variability and decorrelation. 

For scenarios where noise should follow a smooth wavy pattern, `gen_wavydims1(n, p, theta)` generates dimensions as

$$
X_j = \alpha_j \theta + \varepsilon_j, \quad \varepsilon_j \sim N(0, \sigma^2), \quad j = 1, \dots, p,
$$

where each dimension is scaled by a different factor $\alpha_j$, producing structured noise that oscillates along the latent parameter $\theta$, mimicking trends or trajectories observed in real-world data.

The `gen_wavydims2(n, p, x_1)` function extends this approach by applying a non-linear transformation to an existing dimension vector $x_1$:

$$
X_j = \beta_j \, (-1)^{\lfloor j/2 \rfloor} \, x_1^{k_j} + \varepsilon_j, \quad j = 1, \dots, p,
$$

where $k_j$ is a randomly chosen polynomial power, $\beta_j$ is a scaling factor, and $\varepsilon_j$ is small uniform noise.

Finally, `gen_wavydims3(n, p, data)` generates noise for datasets with multiple correlated dimensions. The first three dimensions are small perturbations of the original coordinates $(X_1, X_2, X_3)$, while higher dimensions are constructed via non-linear combinations, including polynomial and trigonometric transformations, e.g.,

$$
X_j = f_j(X_1, X_2, X_3) + \varepsilon_j, \quad j > 3,
$$

producing high-dimensional noise that preserves some geometric correlation with the base structure while introducing additional complexity.

### Multiple cluster examples

By using the shape generators mentioned above, we can create various examples of multiple clusters. The package includes some of these examples, which are described in Table `r knitr::asis_output(ifelse(knitr::is_html_output(), '\\@ref(tab:odd-shape-tb-html)', '\\@ref(tab:odd-shape-tb-pdf)'))`.

```{r}
odd_shapes_tb <- tibble(fun = c("make_mobiusgau",
                                "make_multigau",
                                "make_curvygau",
                                "make_klink_circles",
                                "make_chain_circles",
                                "make_klink_curvycycle",
                                "make_chain_curvycycle",
                                "make_gaucircles",
                                "make_gaucurvycycle",
                                "make_onegrid",
                                "make_twogrid_overlap",
                                "make_twogrid_shift",
                                "make_shape_para",
                                "make_three_clust_"), 
                        exp = c(
    "Möbius-like cluster combined with a Gaussian.",
    "Multiple Gaussian clusters in high-dimensional space.",
    "Curvilinear cluster with a Gaussian cluster.",
    "K-link circular clusters (non-linear circular patterns).",
    "Chain-like circular clusters connected sequentially.",
    "K-link curvy cycle clusters (curvilinear loop structures).",
    "Chain-like curvy cycle clusters connected sequentially.",
    "Circular clusters with a Gaussian cluster in the middle.",
    "Curvy circular clusters with a Gaussian cluster in the middle.",
    "Single grid in two dimensions.",
    "Two overlapping grids.",
    "Two grids shifted relative to each other.",
    "Parallel shaped clusters.",
    "Three clusters with different shapes. (eg:- 01, 02, ..., 20)"))
```

```{r odd-shape-tb-html, eval=knitr::is_html_output()}
odd_shapes_tb |> 
  kable(caption = "cardinalR multiple clusters generation functions", col.names = c("Function", "Explanation")) 
```

```{r odd-shape-tb-pdf, eval=knitr::is_latex_output()}
odd_shapes_tb |> 
  kable(caption = "cardinalR multiple clusters generation functions", format="latex", col.names = c("Function", "Explanation"), booktabs = T)  |>
  column_spec(1, width = "3.5cm") |>
  column_spec(2, width = "8.5cm")
```

### Additional functions

The package includes various supplementary tools in addition to the shape generating functions mentioned earlier. These tools allow users to create background noise, randomize the rows of the data, relocate clusters, generate a vector whose product and sum are approximately equal to a target value, rotate structures, and normalize the data. Table `r knitr::asis_output(ifelse(knitr::is_html_output(), '\\@ref(tab:add-tb-html)', '\\@ref(tab:add-tb-pdf)'))` details these functions.

```{r}
add_fun_tb <- tibble(fun = c("gen_bkgnoise",
                            "randomize_rows",
                            "relocate_clusters",
                            "gen_nproduct",
                            "gen_nsum",
                            "gen_rotation",
                            "normalize_data"), 
                        exp = c("Adds background noise.",
                                "Randomizes the rows.",
                                "Relocates the clusters.",
                                "Generates a vector of positive integers whose product is approximately equal to a target value.",
                                "Generates a vector of positive integers whose summation is approximately equal to a target value.", 
                                "Generates rotations.", 
                                "Normalizes data."))
```

```{r add-tb-html, eval=knitr::is_html_output()}
add_fun_tb |> 
  kable(caption = "cardinalR additional functions", col.names = c("Function", "Explanation")) 
```

```{r add-tb-pdf, eval=knitr::is_latex_output()}
add_fun_tb |> 
  kable(caption = "cardinalR additional functions", format="latex", col.names = c("Function", "Explanation"), booktabs = T)  |>
  column_spec(1, width = "4cm") |>
  column_spec(2, width = "8cm")
```

# Application

<!-- ## Assessing the performance of dimension reduction on different geometric structures in high-dimensions -->

This section illustrates the use of package by generating a synthetic dataset to evaluate the performance of six popular dimension reduction techniques: Principal Component Analysis (PCA) [@jolliffe2011], t-distributed stochastic neighbor embedding (tSNE) [@laurens2008], uniform manifold approximation and projection (UMAP) [@leland2018], potential of heat-diffusion for affinity-based trajectory embedding (PHATE) algorithm [@moon2019], large-scale dimensionality reduction Using triplets (TriMAP) [@amid2019], and pairwise controlled manifold approximation (PaCMAP) [@yingfan2021].

The following code generates a dataset of five clusters, positioned with equal inter-cluster distances in $4\text{-}D$ space (`r knitr::asis_output(if (knitr::is_html_output()) { "Figure \\@ref(fig:highd-data)"} else { "Figure \\@ref(fig:highd-proj)"})`). Each cluster was chosen to reflect distinct geometric and topological properties, allowing us to test how well DR methods preserve both local and global structures. The *helical spiral* cluster is designed to evaluate methods on elongated, twisting structures that challenge linear embeddings such as PCA and require preservation of curvilinear continuity. The *hemisphere* provides a curved surface with partial coverage of a $3\text{-}D$ manifold, useful for testing neighborhood preservation and unfolding in algorithms like UMAP and tSNE. The *uniform cube* represents isotropic, uniformly distributed data and serves as a control cluster with simple geometric structure to assess baseline embedding fidelity. The *cone* introduces variable density along one axis, mimicking structures where point density changes with geometry, helping evaluate how well algorithms maintain relative distances in non-uniform distributions. Finally, the *Gaussian* cluster is a standard multivariate normal distribution, included to assess algorithm performance on simple, spherical, high-density clusters. Together, these clusters create a challenging synthetic dataset suitable for benchmarking and exploring the strengths and weaknesses of different dimensionality reduction techniques.

```{r gen-five-clust-data, echo=TRUE}

positions <- geozoo::simplex(p=4)$points
positions <- positions * 0.8

## To generate data
five_clusts <- gen_multicluster(n = c(2250, 1500, 750, 1250, 1750), k = 5,
                       loc = positions,
                       scale = c(0.4, 0.35, 0.3, 1, 0.3),
                       shape = c("helicalspiral", "hemisphere", "unifcube", 
                                 "cone", "gaussian"),
                       rotation = NULL,
                       is_bkg = FALSE)
```

The five clusters have different geometric structures and each contain different number of points. Specifically, the helical spiral cluster includes $2250$ points and was generated with a scale parameter of $0.4$. The hemisphere cluster consists of $1500$ points with a scale parameter of $0.35$. The uniform cube-shaped cluster contains $750$ points and uses a scale parameter of $0.3$. The blunted cone cluster includes $1250$ points, generated with a scale parameter of $1$. Finally, the Gaussian-shaped cluster contains $1750$ points and was generated with a scale parameter of $0.3$.

```{r highd-data, eval=knitr::is_html_output(), fig.cap="`langevitour` output showing five synthetic clusters with distinct geometric structures: a helical spiral, a hemisphere, a uniform cube, a cone, and a Gaussian cluster."}

langevitour::langevitour(five_clusts[, -5], group = five_clusts$cluster, levelColors = c('#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e'))
```

```{r five-clusts-projections1}
scaled_data <- scale_data_manual(five_clusts[, -5])

## First projection
projection <- cbind(
  c(-0.59692,0.46414,0.42436,-0.10048),
  c(-0.54999,-0.67673,-0.03631,-0.01193))

proj_obj1 <- get_projection(projection = projection, 
                            proj_scale = 1.23, 
                            scaled_data = scaled_data, 
                            axis_param = list(limits = 1,
                                              axis_scaled = 0.8, 
                                              axis_pos_x = -0.9, 
                                              axis_pos_y = -0.9, 
                                              threshold = 0.05))

proj_obj1[["cluster"]] <- as.character(five_clusts$cluster)

five_clusts_proj1 <- plot_proj(
  proj_obj = proj_obj1, 
  point_param = c(1.5, 0.2), # size, alpha, color
  plot_limits = c(-1.1, 1), 
  title = "a1", 
  cex = 2, 
  axis_text_size = 4,
  is_color = TRUE) + scale_color_manual(values = c('#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e')) +
  theme(legend.text = element_text(size = 10))

```

```{r five-clusts-projections2}
## Second projection
projection <- cbind(
  c(0.34673,-0.35774,0.66272,0.27298),
  c(0.24023,0.01170,-0.41886,0.72707))

proj_obj2 <- get_projection(projection = projection, 
                            proj_scale = 1.23, 
                            scaled_data = scaled_data, 
                            axis_param = list(limits = 1,
                                              axis_scaled = 0.8, 
                                              axis_pos_x = -0.9, 
                                              axis_pos_y = -0.9, 
                                              threshold = 0.07))

proj_obj2[["cluster"]] <- as.character(five_clusts$cluster)

five_clusts_proj2 <- plot_proj(
  proj_obj = proj_obj2, 
  point_param = c(1.5, 0.2), # size, alpha, color
  plot_limits = c(-1.1, 1.2), 
  title = "a2", 
  cex = 2, 
  axis_text_size = 4,
  is_color = TRUE) + scale_color_manual(values = c('#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e')) +
  theme(legend.text = element_text(size = 10))
```

```{r five-clusts-projections3}
## Third projection
projection <- cbind(
  c(0.47388,-0.20984,-0.56560,0.41644),
  c(-0.51124,-0.60184,0.06463,0.36627))

proj_obj3 <- get_projection(projection = projection, 
                            proj_scale = 1.23, 
                            scaled_data = scaled_data, 
                            axis_param = list(limits = 1,
                                              axis_scaled = 0.8, 
                                              axis_pos_x = -0.9, 
                                              axis_pos_y = -0.9, 
                                              threshold = 0.05))

proj_obj3[["cluster"]] <- as.character(five_clusts$cluster)

five_clusts_proj3 <- plot_proj(
  proj_obj = proj_obj3, 
  point_param = c(1.5, 0.2), # size, alpha, color
  plot_limits = c(-1.1, 1.1), 
  title = "a3", 
  cex = 2, 
  axis_text_size = 4,
  is_color = TRUE) + scale_color_manual(values = c('#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e')) +
  theme(legend.text = element_text(size = 10))

```

```{r highd-proj, eval=knitr::is_latex_output(), fig.pos='H', fig.cap="Three $2\\text{-}D$ projections from $4\\text{-}D$, for the five clusters data. The helical spiral cluster is represented in dark green, the hemisphere cluster in orange, the uniform cube-shaped cluster in purple, the blunted cone cluster in pink, and the Gaussian-shaped cluster in light green."}
#| fig-width: 12
#| fig-height: 4

five_clusts_proj1 + five_clusts_proj2 + five_clusts_proj3 +
  plot_layout(ncol = 3, guides = "collect") 
```

```{r layouts}

tsne_data <- read_rds("data/five_clusts/five_clusts_tsne_perplexity_30.rds") 

nldr1 <- tsne_data |>
  ggplot(aes(x = tSNE1,
             y = tSNE2,
             color = cluster))+
  geom_point(alpha=0.1, size=1) +
  interior_annotation("a", c(0.08, 0.93)) + 
  scale_color_manual(values = c('#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e')) +
  theme(aspect.ratio = 1,
        legend.text = element_text(size = 10)) 

umap_data <- read_rds("data/five_clusts/five_clusts_umap_n-neigbors_15_min-dist_0.1.rds") 

nldr2 <- umap_data |>
  ggplot(aes(x = UMAP1,
             y = UMAP2,
             color = cluster))+
  geom_point(alpha=0.1, size=1) +
  interior_annotation("b", c(0.08, 0.93)) + 
  scale_color_manual(values = c('#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e')) +
  theme(aspect.ratio = 1,
        legend.text = element_text(size = 10)) 

phate_data <- read_rds("data/five_clusts/five_clusts_phate_knn_5.rds") 

nldr3 <- phate_data |>
  ggplot(aes(x = PHATE1,
             y = PHATE2,
             color = cluster))+
  geom_point(alpha=0.1, size=1) +
  interior_annotation("c", c(0.08, 0.93)) + 
  scale_color_manual(values = c('#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e')) +
  theme(aspect.ratio = 1,
        legend.text = element_text(size = 10)) 

trimap_data <- read_rds("data/five_clusts/five_clusts_trimap_n-inliers_12_n-outliers_4_n-random_3.rds") 

nldr4 <- trimap_data |>
  ggplot(aes(x = TriMAP1,
             y = TriMAP2,
             color = cluster))+
  geom_point(alpha=0.1, size=1) +
  interior_annotation("d", c(0.08, 0.93)) + 
  scale_color_manual(values = c('#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e')) +
  theme(aspect.ratio = 1,
        legend.text = element_text(size = 10))  

pacmap_data <- read_rds("data/five_clusts/five_clusts_pacmap_n-neighbors_10_init_random_MN-ratio_0.5_FP-ratio_2.rds") 

nldr5 <- pacmap_data |>
  ggplot(aes(x = PaCMAP1,
             y = PaCMAP2,
             color = cluster))+
  geom_point(alpha=0.1, size=1) +
  interior_annotation("e", c(0.08, 0.93)) + 
  scale_color_manual(values = c('#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e')) +
  theme(aspect.ratio = 1,
        legend.text = element_text(size = 10)) 

pca_data <- read_rds("data/five_clusts/five_clusts_pca.rds") 

nldr6 <- pca_data |>
  ggplot(aes(x = pca1,
             y = pca2,
             color = cluster))+
  geom_point(alpha=0.1, size=1) +
  interior_annotation("f", c(0.08, 0.93)) + 
  scale_color_manual(values = c('#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e')) +
  theme(aspect.ratio = 1,
        legend.text = element_text(size = 10)) 
```

UMAP, PHATE, TriMAP, and PaCMAP effectively separate the five clusters and show the preservation of the global structure (Figure \@ref(fig:fig-nldr-layouts)). However, PHATE reveals three non-linear clusters, even though two of them do not show non-linearity. UMAP, TriMAP, and PaCMAP successfully maintain the local structures of the data. In contrast, tSNE divides the non-linear cluster into sub-clusters. Also, tSNE fails to preserve the distances between the clusters. PCA, on the other hand, preserves the local structures of the clusters, but some clusters are incorrectly merged that should remain distinct.

```{r, label = "fig-nldr-layouts", fig.pos="H", fig.cap="Six different dimension reduction representations of the five clusters data using default hyperparameter settings: (a) tSNE, (b) UMAP, (c) PAHTE, (d) TriMAP, (e) PaCMAP, and (f) PCA."}

nldr1 + nldr2 + nldr3 +
  nldr4 + nldr5 + nldr6 +
  plot_layout(ncol = 3, guides = "collect")
```

# Conclusion

The `cardinalR` package introduces a flexible framework for generating high-dimensional data structures with well-defined geometric properties. It addresses an important need in the evaluation of clustering, machine learning, and DR methods by enabling the construction of customized datasets with interpretable structures, noise characteristics, and clustering arrangements. In this way, `cardinalR` complements existing packages such as `geozoo`, `snedata`, and `mlbench`, while extending the scope to higher dimensions and more complex shapes.

The motivation for developing this package originated from the need to design a perception–misperception experiment, aimed at investigating how well NLDR methods preserve inter-cluster structure. To conduct this study, we required simulated datasets with carefully controlled geometric and clustering properties. While some existing packages provided useful starting points, none fully supported the creation of flexible, high-dimensional data with the specific structural variations needed for our experiment. Developing these generators for research purposes gradually led to the design of `cardinalR` as a general-purpose package, so that other researchers can benefit from the same tools for simulation, benchmarking, and teaching.

The included structures cover a wide range of diagnostic settings. Branching shapes facilitate the study of continuity and topological preservation, the Scurve with a hole allows investigation of incomplete manifolds, and clustered spheres assess separability on curved surfaces. The Möbius strip introduces challenges from non-orientable geometry, while gridded cubes and pyrholes test spatial regularity and clustering in sparse, non-convex regions.

These structures are designed to support not only algorithm diagnostics, but also teaching high-dimensional concepts, benchmarking reproducibility, and evaluating hyperparameter sensitivity. By allowing users to adjust dimensionality, sample size, noise, and clustering properties, the package promotes transparent experimentation and comparative model evaluation.

Future extensions of `cardinalR` may include biologically inspired or application-driven data structures would further broaden its utility in domains such as bioinformatics, forensic science, and spatial analysis.

<!-- - Branching: These functions create a controlled environment for testing how effectively various algorithms preserve branching topology and continuity in their low-dimensional embeddings. -->

<!-- - Scurve with a hole allowing for evaluation of how well algorithms handle incomplete manifolds or missing local structure. -->

<!-- - clusteredsphere: This structure allows for cluster separation on curved manifolds in high-dimensional space and can be used to test the ability of NLDR methods and clustering algorithms to detect spherical clusters of different sizes and separations. -->

<!-- - Mobius: The core geometric structure is a Mobius strip—a classic one-sided surface with a half-twist—useful for evaluating how well methods capture non-orientability and twisted manifolds. -->

<!-- - Grided cube: This function is useful for assessing how algorithms preserve uniformly spaced data in high-dimensional spaces. -->

<!-- - Pyrholes: This structure is useful for testing clustering and NLDR algorithms on non-convex and sparse high-dimensional shapes. -->

<!-- The application of our high-dimensional data generation package to evaluate the interplay between dimensionality reduction, nuisance variables, and hierarchical clustering yielded several key insights. The ability to generate synthetic datasets with well-defined underlying structures, coupled with the controlled introduction of nuisance variables, provided a valuable platform for assessing the robustness of downstream unsupervised learning techniques. -->

<!-- Our findings demonstrated that the choice of dimensionality reduction method significantly impacted the ability of hierarchical clustering to recover the true underlying clusters. Methods that effectively preserved the global structure of the data, as defined by our generation process, generally led to more accurate and interpretable hierarchical clustering results. However, the presence of nuisance variables often confounded the low-dimensional embeddings, making it more challenging for hierarchical clustering to separate truly distinct groups. This highlights a critical consideration in real-world data analysis, where unmeasured or latent factors can obscure the signal of interest. -->

<!-- The hierarchical clustering analysis itself, and the choice of linkage criteria, also played a crucial role. Different linkage methods revealed varying degrees of sensitivity to the distorted representations caused by the nuisance variables. For instance, methods that prioritize compact clusters might have been more susceptible to being misled by variance introduced by nuisance factors, while others focusing on the distance between clusters might have shown more resilience. The dendrograms generated by hierarchical clustering provided a visual means to explore the relationships between samples and the potential influence of nuisance, although determining the optimal number of clusters remained a challenge in the presence of these confounding factors. -->

<!-- This application underscores the utility of our data generation package as a powerful tool for controlled experimentation in unsupervised learning. By providing the ground truth cluster assignments and the ability to systematically manipulate data characteristics like dimensionality, geometric structure, and the presence of nuisance variables, researchers can gain a deeper understanding of the strengths and limitations of various DR and clustering algorithms. This controlled environment allows for a more objective evaluation than often possible with real-world datasets where the underlying structure is unknown. -->

<!-- One limitation of this particular application was the specific type and magnitude of the nuisance variables introduced. Future work could explore a wider range of nuisance types (e.g., batch effects, technical noise with specific distributions) and their varying degrees of influence on different DR and clustering methodologies. Furthermore, investigating strategies for mitigating the impact of nuisance variables, either during the DR step or within the clustering process itself, would be a valuable extension. -->

<!-- In conclusion, this example demonstrates the critical role of synthetic data generation in dissecting the complex interactions within unsupervised learning pipelines. Our package provides a flexible and controlled means to create such data, enabling researchers to systematically evaluate the performance and robustness of dimensionality reduction and clustering algorithms under well-defined conditions, including the presence of confounding factors. This capability contributes to a more rigorous and informed approach to high-dimensional data analysis. -->

# Acknowledgements

The source material for this paper is available at [github.com/JayaniLakshika/paper-cardinalR](https://github.com/JayaniLakshika/paper-cardinalR).  

This article is created using \CRANpkg{knitr} [@yihui2015] and \CRANpkg{rmarkdown} [@yihui2018] in R with the `rjtools::rjournal_article` template. These `R` packages were used for this work: `cli` [@gabor2025], `tibble` [@kirill2023], `gtools` [@gregory2023], `dplyr` [@hadley2023], `stats` [@core2025], `tidyr` [@hadley2024], `purrr` [@hadley2025], `mvtnorm` [@alan2009], `geozoo` [@barret2016], and `MASS` [@venables2002]. 
